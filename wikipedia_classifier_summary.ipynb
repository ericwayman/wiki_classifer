{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some prelimnary analysis of the wikipedia data set found by scraping the categories:\n",
    "* Rare diseases\n",
    "* Infectious diseases\n",
    "* Cancer\n",
    "* Congenital disorders\n",
    "* Organs\n",
    "* Machine learning algorithms\n",
    "* Medical Devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import subprocess\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> Rare_diseases</td>\n",
       "      <td> &lt;p&gt;A &lt;b&gt;rare disease&lt;/b&gt;, also referred to as ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> Rare_diseases</td>\n",
       "      <td> &lt;p&gt;&lt;b&gt;13q deletion syndrome&lt;/b&gt; is a rare gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> Rare_diseases</td>\n",
       "      <td> &lt;p&gt;&lt;b&gt;2-hydroxyglutaric aciduria&lt;/b&gt; is a grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> Rare_diseases</td>\n",
       "      <td> &lt;p&gt;&lt;b&gt;3C syndrome&lt;/b&gt;, also known as &lt;b&gt;CCC dy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> Rare_diseases</td>\n",
       "      <td> &lt;p&gt;&lt;b&gt;3q29 microdeletion syndrome&lt;/b&gt; is a rar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text\n",
       "0  Rare_diseases  <p>A <b>rare disease</b>, also referred to as ...\n",
       "1  Rare_diseases  <p><b>13q deletion syndrome</b> is a rare gene...\n",
       "2  Rare_diseases  <p><b>2-hydroxyglutaric aciduria</b> is a grou...\n",
       "3  Rare_diseases  <p><b>3C syndrome</b>, also known as <b>CCC dy...\n",
       "4  Rare_diseases  <p><b>3q29 microdeletion syndrome</b> is a rar..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"full_data.csv\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>percent_of_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>                      Cancer</td>\n",
       "      <td>  35</td>\n",
       "      <td>  5.295008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>        Congenital_disorders</td>\n",
       "      <td> 180</td>\n",
       "      <td> 27.231467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>         Infectious_diseases</td>\n",
       "      <td> 103</td>\n",
       "      <td> 15.582451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> Machine_learning_algorithms</td>\n",
       "      <td>  53</td>\n",
       "      <td>  8.018154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>             Medical_devices</td>\n",
       "      <td>  60</td>\n",
       "      <td>  9.077156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>            Organs_(anatomy)</td>\n",
       "      <td>  30</td>\n",
       "      <td>  4.538578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>               Rare_diseases</td>\n",
       "      <td> 200</td>\n",
       "      <td> 30.257186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      category  text  percent_of_total\n",
       "0                       Cancer    35          5.295008\n",
       "1         Congenital_disorders   180         27.231467\n",
       "2          Infectious_diseases   103         15.582451\n",
       "3  Machine_learning_algorithms    53          8.018154\n",
       "4              Medical_devices    60          9.077156\n",
       "5             Organs_(anatomy)    30          4.538578\n",
       "6                Rare_diseases   200         30.257186"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = df.groupby('category').count().reset_index()\n",
    "total= class_counts[\"text\"].sum()\n",
    "class_counts[\"percent_of_total\"]=class_counts[\"text\"].apply(lambda x: x*100/float(total) )\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can see the data is fairly imbalacned with rare_diseases being the most represented by accounting for 30.25% of the total labels and congenital_disorders second with 27.23%.  So when judging the accuracy of our models through cross validation, we need to compare to the baseline strawman model of simply predicting Rare_diseases for any page and achieving ~30% accuracy, as opposed to only ~14.28% if the class labels were more even balanced in the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My code base consists of the following files:\n",
    "* config.py\n",
    "* wiki_scraper.py\n",
    "* train_and_score_models.py\n",
    "* wiki_scraper.py\n",
    "\n",
    "**config.py** defines a config object that is imported in the other scripts to configure settings over the whole project.  Here you can define the categories for the classification, the models to be used and the paths and names of the data files.\n",
    "\n",
    "Running **wiki_scraper.py** scrapes the web pages under the categories defined in config.py and saves them to a csv called \"full_data.csv\".\n",
    "So far the scraper only pulls the first 200 pages for a category and doesn't include the sub categories.  If I were to continue the project, these would be features I'd want to implement to get a more extensive data set.  The is careful only to pull the text in the pages to make sure there is no leakage from extracting the categories of the article as well. \n",
    "\n",
    "**train_and_score_models.py** is a a script that  first loads the full_data.csv as a Pandas Dataframe and then runs some preprocessing before training models on the data and scoring using n-fold cross validation.\n",
    " \n",
    " I noticed that some pages appeared under multiple categories, so as part of the preprocessing, I remove duplicate pages by keeping only the last occurence so that each page only has one label.  Also, I trimmed the articles to speed up the process of training the models while tweaking my code, but also noticed a slight improvement in accuracy.  I also, experimented with stemming the words, but didn't notice any significant improvement, and also I had some encoding issues that I had to debug when preproecessing the new documents for prediction, so in the end I decided it wasn't worth it.  however the function \"text_transforms\" is called to each row of the data frame during preprocessing, so any future experiments to transform the text can be added to this function.\n",
    " \n",
    " For features I used the TF-IDF scores from the TfidfVectorizer in the sklearn feature_extraction.text library.  \n",
    " \n",
    " For models I experimented with an AdaBoostClassifier, Logistic Regression, Multinomial naive bayes and a Random forest classifier.  Also, for a final model I ensembled the models by averaging the predicted probabilities for each class and predicting the class with the highest average probability.  I experimented with tweaking some of the models in the ensemble and various model parameters, but my tuning was hardly exhaustive.  Some results are included below.\n",
    "\n",
    "Lastly, **predict_categories.py** takes in user input in the form of either a wikipedia full link or a tail of the link (i.e. https://en.wikipedia.org/wiki/Aphallia or Aphallia) and prints out the predicted probabilities for each class and for each model, as well as the predicted probability and class predicted for the final ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the mean accuracy scores for each model and the ensembled when using 10 fold cross validation.  No stemming was performed, but each article was trimmed to 300 characters.  The Naive Bayes was dropped because it lowered performance of the ensembler.  In this case, the random forest performed the best- even better than the ensemble model \n",
    "Mean accuracy across CV folds for each model:\n",
    "* ada_boost_clf: 0.57967648057\n",
    "* logistic_clf: 0.599275353351\n",
    "* random_forest_clf: 0.742836364322\n",
    "* Average accuracy of the ensemble: 0.737909516381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   6,   1,   0,   0,   0,  22],\n",
       "       [  0, 125,   0,   0,   1,   0,  52],\n",
       "       [  0,   2,  87,   0,   0,   0,  14],\n",
       "       [  0,   3,   0,  48,   0,   0,   2],\n",
       "       [  0,   6,   2,   0,  40,   0,  12],\n",
       "       [  0,  10,   0,   0,   0,   6,  14],\n",
       "       [  0,  31,   1,   0,   0,   0, 150]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_data = pd.read_csv(\"prediction_data.csv\")\n",
    "labels=prediction_data[\"labels\"]\n",
    "preds=prediction_data[\"predictions\"]\n",
    "confusion_matrix(y_true=labels,y_pred=preds)\n",
    "#C_i,j is entries actually in group i but predicted in group j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cancer',\n",
       " 'Congenital disorders',\n",
       " 'Infectious diseases',\n",
       " 'Machine learning algorithms',\n",
       " 'Medical Devices',\n",
       " 'Organs',\n",
       " 'Rare diseases']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted labels for reference in the confusion matrix\n",
    "sorted([\"Rare diseases\",\n",
    "\"Infectious diseases\",\n",
    "\"Cancer\",\n",
    "\"Congenital disorders\",\n",
    "\"Organs\",\n",
    "\"Machine learning algorithms\",\n",
    "\"Medical Devices\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the confusion matrix we observe that as expected, most errors occur by predicting a class to belong in rare diseases.  This most likely is partially a result of rare diseases being the most common label.  Enlarging the data set and in particular, finding more training for the smaller classes would like help improve this accuracy.  The model seems to get confused between congenital disorders and rare diseases as there 52 examples of congential disorders classified as rare diseases, and 31 examples of rare diseases being classified as congenital disorders.  This is expected, as conceptually the two categories are more similar compared to the other 5.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future work I would improve the web scraping ability to find more articles when the articles span multiple pages, and I would also would scrape the sub-categories as well. \n",
    "\n",
    "I would also experiment with more feature engineering and parameter tuning.  Other features I would experiment with would be a word2vec embedding, TFIDF on the pagraph titles, article length count, average word length, etc.\n",
    "\n",
    "In terms of models I would also like to implement a gradient boosted tree model and a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
